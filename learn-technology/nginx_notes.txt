## nginx-notes
## create at 2018.1.2


在ubuntu下开启nginx服务：必须用sudo ，不然只能在前台运行
在nginx中,nginx默认将其主进程的pid写入到 /usr/local/nginx/nginx/pid。
	保存主进程号,方便对nginx进行操作。例如更新配置文件,关闭nginx服务


用 ～ 来表示locatiion开启正则匹配（匹配.php结尾的文件s）
location ~ \.php${
	fastcgi_pass 127.0.0.1.9000;
	fastcgi_index index.php;
	include fascgi.conf;
}
limit_req_zone $binary_remote_addr zone=one 10m rate=15r/s
名称为zone，大小为10m，平均处理的请求频率不超过每秒15次。
速度可以设置为每秒处理请求书和每分钟处理请求数。


sudo /usr/local/nginx/nginx

1、关闭nginx服务
	sudo ./nginx -s stop
	pkill -9 nginx (强行关闭)
	
	
	从容关闭:
		ps -ef | grep nginx  // 找到nginx的主进程号
		kill -QUIT (nginx的主进程号)
		
	如果不想先查找进程号的话,可以直接使用命令
	 kill -QUIT ` cat /run/nginx.pid`（后面的是从保存nginx的主进程号的文件中读取数据）
	 启动nginx的时候保存到制定目录
	 当关闭nginx的时候,再从指定目录读取文件
	 
	
二、学习网址
	1、Nginx开发从入门到精通
		http://tengine.taobao.org/book/
	2、gitbook的网址
		https://wizardforcel.gitbooks.io/nginx-doc/content/Text/1.2_nginxchswhyuseit.html
	3、一个评价比较高的博客
		http://www.cnblogs.com/jingmoxukong/p/5945200.html
	4、讲nginx的一个博客
		http://www.cnblogs.com/languoliang/archive/2013/04/01/nginx.html
		nginx的日志文件位置:、/var/log/nginx
		nginx的配置文件位置:/etc/nginx
		nginx的启动文件位置:/usr/sbin/nginx
			在/etc/init.d/下创建了启动脚本nginx
		nginx的虚拟主机目位置：/usr/share/nginx/www
	5、gitbook上的nginx中文官方文档
		https://wizardforcel.gitbooks.io/nginx-doc/content/
	6、wiki nginx 
	7、简书
		https://www.jianshu.com/p/bed000e1830b
	
upstream big_server_com{
	server 127.0.0.1:8000 weight=5;
	server 127.0.0.1:8002 weight=3;
}

server{
	listen 80;
	server_name big.server.com;
	location /{
		proxy_pass http://big_server_com
	}
}
	
三、笔记
1、nginx性能高的原因和其架构是分不开的。
	1.1、在unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。
	1.2、nginx是以多进程的方式来工作的，当然nginx也是支持多线程的方式的，只是我们主流的方式还是多进程的方式,也是nginx的默认方式。
	1.3、多个worker进程之间是对等的,他们同等竞争来自客户端的请求,各个进程之间是独立的,也就是说：一个请求只能在一个worker进程中处理,一个worker进程
		不可能处理别的请求。
		而且，worker进程的个数是可以设置的,一般与cpu的核数一致。
	1.4、nginx在启动后，会有一个master进程和多个worker进程。
		master进程的作用：
			master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，
				当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。
			worker进程的主要作用：处理基本的基本的网络事件。
2、worker进程是如何处理请求的？
	根据“二、学习网址的第一个：”，说的是多个worker进程平等竞争，就是当有请求到来以后,多个进程来竞争这一把锁。谁抢到了，那么就由谁来执行这个请求。
	也就是获取锁。
3、nginx的这种多进程的工作方式的好处是什么？
	首先，对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。
	其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快启动新的worker进程。
4、nginx是如何实现高并发的？
	采用异步非阻塞的事件处理机制。eagain
	它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。
	这种机制正好解决了我们上面的两个问题，拿epoll为例(在后面的例子中，我们多以epoll为例子，以代表这一类函数)，当事件没准备好时，放到epoll里面，
	事件准备好了，我们就去读写，当读写返回EAGAIN时，我们将它再次加入到epoll里面。这样，只要有事件准备好了，我们就去处理它，
	只有当所有事件都没准备好时，才在epoll里面等着。这样，我们就可以并发处理大量的并发了。
	这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，
	切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。
	与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。
	并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。
	我之前有对连接数进行过测试，在24G内存的机器上，处理的并发请求数达到过200万。现在的网络服务器基本都采用这种方式
5、一个基本的web服务器来说，事件通常有三种类型，网络事件、信号、定时器。从上面的讲解中知道，网络事件通过异步非阻塞可以很好的解决掉。如何处理信号与定时器？
6、nginx的配置系统
	在nginx.conf配置文件中,包含了若干个配置项。
6.1、配置项由配置指令和指令参数构成。
	配置指令
		配置指令是一个字符串，可以用单引号或者双引号括起来，也可以不括。但是如果配置指令包含空格，一定要引起来。
	指令参数
		指令参数也就是配置指令对应的配置值。使用一个或者多个空格或者TAB字符与指令分开。
		指令的参数有一个或者多个TOKEN串组成。TOKEN串之间由空格或者TAB键分隔。
		
		TOKEN串分为简单字符串或者是复合配置块。
			简单字符串，这个配置指令的参数全部由简单字符串构成。例如：
				error_page   500 502 503 504  /50x.html;
			复合配置块即是由大括号括起来的一堆内容。一个复合配置块中可能包含若干其他的配置指令。例如：
				location / {
					root   /home/jizhao/nginx-book/build/html;
					index  index.html index.htm;
				}
6.2、指令上下文
nginx.conf中的配置信息，根据其逻辑上的意义，对它们进行了分类，也就是分成了多个作用域，或者称之为配置指令上下文。不同的作用域含有一个或者多个配置项。

当前nginx支持的几个指令上下文：
main:	nginx在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。
http:	与提供http服务相关的一些配置参数。例如：是否使用keepalive啊，是否使用gzip进行压缩等。
server:	http服务上支持若干虚拟主机。每个虚拟主机一个对应的server配置项，配置项里面包含该虚拟主机相关的配置。在提供mail服务的代理时，也可以建立若干server.每个server通过监听的地址来区分。
location:	http服务中，某些特定的URL对应的一系列配置项。
mail:	实现email相关的SMTP/IMAP/POP3代理时，共享的一些配置项（因为可能实现多个代理，工作在多个监听地址上）。

指令上下文，可能有包含的情况出现。例如：通常http上下文和mail上下文一定是出现在main上下文里的。
在一个上下文里，可能包含另外一种类型的上下文多次。
例如：如果http服务，支持了多个虚拟主机，那么在http上下文里，就会出现多个server上下文。
			
四、疑问
	1、如何实现公平竞争？

五、杂记
	1、nginx使用基于事件的模型和依赖于操作系统的机制来高效地在工作进程间分配请求
	2、Geo模块
		这个模块产生变量，这个变量的值依据客户端的ip地址来进行创建
六、nginx日志
1、选择一个负载均衡的方法
	1.1、IP Hash
		这个方法确保了来自相同的ip的请求都可以请求到相同的服务器地址除非这个服务器不可用。
		upstream backend{
			ip_hash;
			server backend1.example.com
			server backend2.example.com
			server backernd3.example.com down // 表示这个服务器地址暂时不可用,如果有客户端的ip经过hash之后请求到这里
											  // ,那么这个请求会自动分派到这个服务器组中的下一个服务器上。
		}
	1.2、Round Robin(权重)
		根据权重的大小来分配请求(默认的权重是1)
		upstream backend{
			server backend1.example.com  // 这个是默认的权重 weight=1
			server backend2.example.com	 weight=5; // 分配指定权重 
			server 172.168.1.1 backup; // 表示只有当其它服务器都不可达的时候,请求才会到这个服务器上。
			
		}
	1.3、Least Connections
		请求将会被分发到连接数量最少的服务器上(将权重考虑在内)
		A request is sent to the server with the least the number of active aconnections with server weights taken into consideration
		upstream backend{
			least_conn;
			server backend1.example.com;
			server backend2.example.com;
			
		}
	1.4、Generic Hash
		哪儿个服务器接收什么请求取决于用于自定义的key(可以是一个字符串、变量、或者组合)
		例如：这个key可能是一对,客户端的ip和对暗扣或者URI
		upstream backend{
			hash $request_uri constant;
			server backend1.example.com;
			server backend2.example.com;
		}
		
		这个constant变量确保使用ketama的一致哈希负载均衡。根据用户自定义的散列键值,将请求均匀分布在所有upstream内的服务器列表中。
		。如果向upstream中增加服务器或者从upstream组中删除服务起,这样就会哟啊重新映射几个密码，这样。在
		在负载均衡高速缓存服务器或者其他累计状态的应用程序的情况下，将减少未命中降低到最低。
	1.5、Least Time(NGINX Plus only)
			对于每一个请求,nginx plus 选择具有最低平均延迟和最低活动连接数的服务器。其中最低平均延迟时间是根据包括minimun_time计算得到的
			upstream backend{
				least_time header;  
				server backend1.example.com;
				server backend2.example.com;
			}
			header:Time to receive the first byte from the server
			last_byte:Time to receive the full response from the server
2、balance loader
	2.1、max_conns(限制连接的数量)
		通过使用nginx plus，可以限定连接到某个服务器的连接数量，通过max_conns。如果超过了最大链接，这些链接就会被添加到一个队列中。
		同时，可以在这个队列中指定超时时间(表明在这个时间段内，该请求没有被处理,如果超时,客户端会收到一个error)。
		upstream backend{
			server backend1.example.com;
			server backend2.example.com max_conns=3;
			queue 100 timeout=70;
			server backend3.example.com down; 
			server backend4.example.com max_fails=4 fail_timeout=30s;
		}
	down，表示当前的server暂时不参与负载均衡。
	backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。
	max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。
	fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。


3、Reverse proxy(反向代理)

3.1、定义
	指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，
并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。
3.2、优点
	3.2.1、保护了真实的web服务器。(外网只能访问代理服务器，而反向代理服务器上没有真实的数据）
	3.2.2、节省了有点的ip地址资源
	3.2.3、减少web服务器压力,提高相应速度
			反向代理就是通常所说的web服务器加速，它是一种通过在繁忙的web服务器和外部网络之间增加一个高速的web缓冲服务器来降低实际的web服务器的负载的一种技术。
		反向代理是针对web服务器提高加速功能，作为代理缓存，它并不是针对浏览器用户，而针对一台或多台特定的web服务器，它可以代理外部网络对内部网络的访问请求。
	3.2.4、区分动态和静态可缓存内容；
	3.2.5、实现负载均衡，内部可以采用多台服务器来组成服务器集群，外部还是可以采用一个地址访问；
	3.2.6、解决Ajax跨域问题；
	3.2.7、作为真实服务器的缓冲，解决瞬间负载量大的问题；
3.3、
location /{
	root /users/yangyi/www;
	index index.php index.html index.htm;
}

	location /: 表示匹配访问根目录。
	root:指令用于指定访问根目录时，虚拟主机的web目录，这个目录可以是相对路径（相对路径是相对于nginx的安装目录）。也可以是绝对路径。
	index:用于设定我们只输入域名后访问的默认首页地址，有个先后顺序：index.php index.html index.htm，
			如果没有开启目录浏览权限，又找不到这些默认首页，就会报403错误。

		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
		
	