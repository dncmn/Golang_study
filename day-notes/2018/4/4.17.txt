##2018.4.17
##daily-notes

daily-targets
	1.Docker-compose
		能看懂docker-compose.yml文件
		感觉和nginx差不多,像是build,depend on（大概是这个依赖什么的....),version.NetWork，Service等
		同时管理多个服务
	
疑问：

	1、在docker-compose.yml文件中,如果需要一些环境变量,项目里面是怎么处理的？
		1、使用env_file
		2、使用environment
	2、docker-compse启动问题
		比如在启动相关服务比如web服务的时候,有的可能会依赖数据库服务。
		但是虽然服务库这个服务启动了，但是启动是需要消耗时间的，如果这时候mysql还没有完全启动，但是web服务启动启动了
		这时候,web服务就会报错。
		参考网址：
			http://blog.terminus.io/pampas-docker-startup-order/
			
		备注:虽然这个问题，目前还没有遇到，但是记录下来还是可以的
	
我想到的方法：
	1.如果用到的不多的话,不涉及隐私的话,那就可以直接添加进去，使用environment
		如果从安全角度来考虑，可以只写环境变量的名字,启动服务的时候会自己从host主机中搜索
		environment:(设置环境变量。你可以使用数组或字典两种格式)
		  RACK_ENV: development
		  SESSION_SECRET:
	2.将所有的环境变量信息配置在某个具体的文件中，使用env_file
		2.1.env_file: .env
		2.2.env_file:
		  - ./common.env
		  - ./apps/web.env
		  - /opt/secrets.env
		  
		  
思考的问题	  
1、多用户登录的处理？？？
	在本个项目里面,如果多用户登录,会踢掉上一个用户。
	再上一个项目中,多用户登录,没有做任何处理,只是对重要数据加锁,以防止脏数据的产生。
2、读取本地超大文件并以字节流类型发送 ？？？
	像是之前,将csv数据写入到consul中。
更新数据的时候,好像是consul对这个kv-store做了限制,一次单独只能上传这么多,512什么的。
看到这个问题，第一感觉是分割，分割，在分割,然后再分别传输。
有人说参考io.Copy()，io.Pipe

		  
		  
消息队列

	将所有消息推送到消息队列中,然后慢慢来处理。
	
消息队列需要考虑的问题：
	１、消息过多,导致处理不及时。这个队列会如何处理
		如果生产者源源不断地向队列中添加消息,也就是消息量过多,消费者如果处理不及时,这个队列会怎么处理。
		(忽略存在多少消费者的情况，如果存在多个消费者的话)
		

		
		
		
		
		











